import os
import pandas as pd
import requests
import logging
from datetime import datetime, timedelta, timezone
from dotenv import load_dotenv
import time
import sys
from typing import Dict, List, Optional
import numpy as np

# –ò–º–ø–æ—Ä—Ç –∏–∑ core
sys.path.append(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'core'))
from capital_request import CapitalComAPI

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

class EnhancedSentimentAnalyzer:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self):
        self.marketaux_api_key = os.getenv("MARKETAUX_API_TOKEN")
        self.newsapi_key = os.getenv("NEWSAPI_KEY")  # https://newsapi.org/
        #self.alpha_vantage_key = os.getenv("ALPHA_VANTAGE_API_KEY")  # https://www.alphavantage.co/
        
    def get_fear_greed_index(self) -> float:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ —Å—Ç—Ä–∞—Ö–∞ –∏ –∂–∞–¥–Ω–æ—Å—Ç–∏ –æ—Ç CNN"""
        try:
            url = "https://api.alternative.me/fng/?limit=1"
            response = requests.get(url, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                value = float(data['data'][0]['value'])
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º: 0-25 = –æ—á–µ–Ω—å –±–æ—è–∑–ª–∏–≤–æ (0.0-0.25), 75-100 = –æ—á–µ–Ω—å –∂–∞–¥–Ω–æ (0.75-1.0)
                normalized = value / 100.0
                logger.info(f"Fear & Greed Index: {value} (normalized: {normalized:.3f})")
                return normalized
            else:
                logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å Fear & Greed Index")
                return 0.5
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ Fear & Greed Index: {e}")
            return 0.5
    
    def get_news_sentiment_newsapi(self, hours_back: int = 24) -> float:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ sentiment –Ω–æ–≤–æ—Å—Ç–µ–π —á–µ—Ä–µ–∑ NewsAPI"""
        try:
            if not self.newsapi_key:
                logger.warning("NewsAPI key –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return 0.5

            to_date = datetime.now(timezone.utc)
            from_date = to_date - timedelta(hours=hours_back)

            params = {
                'q': 'gold OR DXY OR VIX', # –ó–∞–ø—Ä–æ—Å –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
                'language': 'en',
                'sortBy': 'relevancy',
                'from': from_date.strftime('%Y-%m-%dT%H:%M:%S'),
                'to': to_date.strftime('%Y-%m-%dT%H:%M:%S'),
                'pageSize': 50, # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞—Ç–µ–π –Ω–∞ –∑–∞–ø—Ä–æ—Å
                'apiKey': self.newsapi_key
            }

            response = requests.get("https://newsapi.org/v2/everything", params=params, timeout=30)

            if response.status_code == 200:
                data = response.json()
                articles = data.get('articles', [])

                if articles:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—à—É –≤–Ω—É—Ç—Ä–µ–Ω–Ω—é—é —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ sentiment –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
                    sentiment = self._analyze_sentiment_keywords(articles)
                    logger.info(f"NewsAPI Sentiment: {sentiment:.3f} from {len(articles)} articles")
                    return sentiment
                else:
                    logger.warning("–ù–µ—Ç —Å—Ç–∞—Ç–µ–π –∏–∑ NewsAPI –ø–æ –∑–∞–¥–∞–Ω–Ω—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º")
                    return 0.5
            else:
                logger.warning(f"NewsAPI –æ—à–∏–±–∫–∞: {response.status_code} - {response.text}")
                return 0.5

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ news sentiment –∏–∑ NewsAPI: {e}")
            return 0.5

    def get_news_sentiment_marketaux(self, hours_back: int = 24) -> float:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ sentiment –Ω–æ–≤–æ—Å—Ç–µ–π —á–µ—Ä–µ–∑ MarketAux"""
        try:
            if not self.marketaux_api_key:
                logger.warning("MarketAux API key –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return 0.5
                
            # –í—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω
            to_date = datetime.now(timezone.utc)
            from_date = to_date - timedelta(hours=hours_back)
            
            params = {
                'api_token': self.marketaux_api_key,
                'symbols': 'XAUUSD,DXY,SPY',  # –ó–æ–ª–æ—Ç–æ, –¥–æ–ª–ª–∞—Ä, SP500
                'filter_entities': 'true',
                'language': 'en',
                'published_after': from_date.strftime('%Y-%m-%dT%H:%M:%S'),
                'published_before': to_date.strftime('%Y-%m-%dT%H:%M:%S'),
                'limit': 50
            }
            
            response = requests.get("https://api.marketaux.com/v1/news/all", params=params, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                articles = data.get('data', [])
                
                if articles:
                    all_entity_sentiment_scores = []
                    for article in articles:
                        entities = article.get('entities', [])
                        for entity in entities:
                            score = entity.get('sentiment_score')
                            if score is not None:
                                all_entity_sentiment_scores.append(score)

                    if all_entity_sentiment_scores:
                        avg_sentiment = np.mean(all_entity_sentiment_scores)
                        normalized_sentiment = (avg_sentiment + 1) / 2
                        logger.info(f"MarketAux News Sentiment: {avg_sentiment:.3f} (normalized: {normalized_sentiment:.3f}) from {len(all_entity_sentiment_scores)} entity sentiments")
                        return normalized_sentiment
                    else:
                        logger.warning("–ù–µ—Ç —Å—Ç–∞—Ç–µ–π –∏–ª–∏ —Å—É—â–Ω–æ—Å—Ç–µ–π —Å sentiment scores –≤ MarketAux")
                        return 0.5
                else:
                    logger.warning("–ù–µ—Ç —Å—Ç–∞—Ç–µ–π –∏–∑ MarketAux –ø–æ –∑–∞–¥–∞–Ω–Ω—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º") # –î–æ–±–∞–≤–ª–µ–Ω–æ –¥–ª—è —è—Å–Ω–æ—Å—Ç–∏
                    return 0.5
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ news sentiment –∏–∑ MarketAux: {e}")
            return 0.5
    
    def _analyze_sentiment_keywords(self, articles: List[Dict]) -> float:
        """–ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ sentiment –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º"""
        positive_words = [
            'bullish', 'rise', 'gain', 'growth', 'surge', 'rally', 'boom', 'optimistic',
            'strong', 'increase', 'up', 'higher', 'advance', 'recovery', 'positive'
        ]
        
        negative_words = [
            'bearish', 'fall', 'drop', 'decline', 'crash', 'sell', 'pessimistic',
            'weak', 'decrease', 'down', 'lower', 'retreat', 'recession', 'negative'
        ]
        
        total_score = 0
        total_articles = 0
        
        for article in articles:
            text = (article.get('title', '') + ' ' + article.get('description', '')).lower()
            
            positive_count = sum(1 for word in positive_words if word in text)
            negative_count = sum(1 for word in negative_words if word in text)
            
            if positive_count > 0 or negative_count > 0:
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å—á–µ—Ç –æ—Ç -1 –¥–æ 1, –∑–∞—Ç–µ–º –∫ 0-1
                article_score = (positive_count - negative_count) / max(positive_count + negative_count, 1)
                total_score += (article_score + 1) / 2  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ 0-1
                total_articles += 1
        
        return total_score / max(total_articles, 1)
    
    def get_vix_based_sentiment(self, capital_api: CapitalComAPI) -> float:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ sentiment –Ω–∞ –æ—Å–Ω–æ–≤–µ VIX (–∏–Ω–¥–µ–∫—Å –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏)"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ VIX
            to_date = datetime.now(timezone.utc)
            from_date = to_date - timedelta(hours=48)
            
            vix_data = capital_api.get_historical_prices(
                epic="VIX",
                resolution="HOUR",
                max_points=48,
                from_date=from_date.strftime('%Y-%m-%dT%H:%M:%S'),
                to_date=to_date.strftime('%Y-%m-%dT%H:%M:%S')
            )
            
            if vix_data and 'prices' in vix_data and vix_data['prices']:
                # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ VIX
                latest_vix = float(vix_data['prices'][-1]['closePrice']['bid'])
                
                # VIX –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:
                # < 20: –Ω–∏–∑–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å, –≤—ã—Å–æ–∫–∏–π –æ–ø—Ç–∏–º–∏–∑–º (0.7-1.0)
                # 20-30: —É–º–µ—Ä–µ–Ω–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å, –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π sentiment (0.4-0.7)
                # > 30: –≤—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å, —Å—Ç—Ä–∞—Ö (0.0-0.4)
                
                if latest_vix < 20:
                    sentiment = 0.7 + (20 - latest_vix) / 20 * 0.3  # 0.7-1.0
                elif latest_vix < 30:
                    sentiment = 0.4 + (30 - latest_vix) / 10 * 0.3  # 0.4-0.7
                else:
                    sentiment = max(0.0, 0.4 - (latest_vix - 30) / 20 * 0.4)  # 0.0-0.4
                
                logger.info(f"VIX-based sentiment: {sentiment:.3f} (VIX: {latest_vix:.2f})")
                return sentiment
            else:
                logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ VIX")
                return 0.5
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ VIX sentiment: {e}")
            return 0.5
    
    def get_combined_sentiment(self, capital_api: CapitalComAPI = None) -> Dict[str, float]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ sentiment –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        logger.info("üß† –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö sentiment –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤...")
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        fear_greed = self.get_fear_greed_index()
        news_marketaux = self.get_news_sentiment_marketaux()
        news_newsapi = self.get_news_sentiment_newsapi()
        
        # VIX sentiment (–µ—Å–ª–∏ –µ—Å—Ç—å Capital API)
        vix_sentiment = 0.5
        if capital_api:
            vix_sentiment = self.get_vix_based_sentiment(capital_api)
        
        # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –≤—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Å –≤–µ—Å–∞–º–∏
        weights = {
            'fear_greed': 0.3,
            'news_marketaux': 0.3,
            'news_newsapi': 0.2,
            'vix': 0.2
        }
        
        combined_sentiment = (
            fear_greed * weights['fear_greed'] +
            news_marketaux * weights['news_marketaux'] +
            news_newsapi * weights['news_newsapi'] +
            vix_sentiment * weights['vix']
        )
        
        sentiment_data = {
            'fear_greed': fear_greed,
            'news_marketaux': news_marketaux,
            'news_newsapi': news_newsapi,
            'vix_sentiment': vix_sentiment,
            'combined_sentiment': combined_sentiment,
            'timestamp': datetime.now()
        }
        
        logger.info(f"‚úÖ Combined Sentiment: {combined_sentiment:.3f}")
        logger.info(f"   - Fear & Greed: {fear_greed:.3f}")
        logger.info(f"   - MarketAux News: {news_marketaux:.3f}")
        logger.info(f"   - NewsAPI: {news_newsapi:.3f}")
        logger.info(f"   - VIX-based: {vix_sentiment:.3f}")
        
        return sentiment_data


class GoldTradingDataPipeline:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ —Ç–æ—Ä–≥–æ–≤–ª–µ –∑–æ–ª–æ—Ç–æ–º"""
    
    def __init__(self):
        self.capital_api = CapitalComAPI(
            os.getenv("CAPITAL_API_KEY"),
            os.getenv("CAPITAL_IDENTIFIER"),
            os.getenv("CAPITAL_PASSWORD")
        )
        self.sentiment_analyzer = EnhancedSentimentAnalyzer()
        
    def get_market_data_with_sentiment(self, hours_back: int = 48) -> pd.DataFrame:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å sentiment –∞–Ω–∞–ª–∏–∑–æ–º"""
        try:
            logger.info("üöÄ –ó–∞–ø—É—Å–∫ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –¥–∞–Ω–Ω—ã—Ö...")
            
            # 1. –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
            if not self.capital_api.login_and_get_tokens():
                logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞—Ç—å—Å—è –≤ Capital.com")
                return pd.DataFrame()
            
            # 2. –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ —Ü–µ–Ω–∞—Ö
            instruments = ["GOLD", "DXY", "VIX"]
            price_dfs = []
            
            to_date = datetime.now(timezone.utc)
            from_date = to_date - timedelta(hours=hours_back)
            
            for instrument in instruments:
                logger.info(f"üìä –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {instrument}...")
                
                price_data = self.capital_api.get_historical_prices(
                    epic=instrument,
                    resolution="HOUR",
                    max_points=hours_back,
                    from_date=from_date.strftime('%Y-%m-%dT%H:%M:%S'),
                    to_date=to_date.strftime('%Y-%m-%dT%H:%M:%S')
                )
                
                if price_data and 'prices' in price_data:
                    df = self._convert_price_data_to_df(price_data, instrument)
                    if not df.empty:
                        price_dfs.append(df)
                
                time.sleep(1)  # –£–≤–∞–∂–∞–µ–º API limits
            
            if not price_dfs:
                logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ —Ü–µ–Ω–∞—Ö")
                return pd.DataFrame()
            
            # 3. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ü–µ–Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            combined_df = pd.concat(price_dfs, axis=1)
            combined_df.sort_index(inplace=True)
            combined_df.ffill(inplace=True)
            
            # 4. –ü–æ–ª—É—á–µ–Ω–∏–µ sentiment –¥–∞–Ω–Ω—ã—Ö
            sentiment_data = self.sentiment_analyzer.get_combined_sentiment(self.capital_api)
            
            # 5. –î–æ–±–∞–≤–ª–µ–Ω–∏–µ sentiment –∫ –¥–∞–Ω–Ω—ã–º
            for key, value in sentiment_data.items():
                if key != 'timestamp':
                    combined_df[key] = value
            
            # 6. –†–∞—Å—á–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
            if 'GOLD_Close' in combined_df.columns:
                combined_df = self._add_technical_indicators(combined_df)
            
            logger.info(f"‚úÖ –ü–∞–π–ø–ª–∞–π–Ω –∑–∞–≤–µ—Ä—à–µ–Ω. –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {combined_df.shape}")
            return combined_df
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ –ø–∞–π–ø–ª–∞–π–Ω–µ: {e}")
            return pd.DataFrame()
    
    def _convert_price_data_to_df(self, price_data: dict, instrument: str) -> pd.DataFrame:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –æ —Ü–µ–Ω–∞—Ö –≤ DataFrame"""
        prices_list = []
        
        for price_point in price_data['prices']:
            if 'snapshotTime' in price_point and 'closePrice' in price_point:
                dt_aware = pd.to_datetime(price_point['snapshotTime']).tz_localize('UTC')
                close_price = float(price_point['closePrice']['bid'])
                
                prices_list.append({
                    'Datetime': dt_aware,
                    f'{instrument}_Close': close_price,
                })
        
        if not prices_list:
            return pd.DataFrame()
        
        df = pd.DataFrame(prices_list)
        df.set_index('Datetime', inplace=True)
        return df
    
    def _add_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤"""
        try:
            gold_close = df['GOLD_Close']
            
            # RSI
            df['RSI'] = self._calculate_rsi(gold_close)
            
            # Moving Averages
            df['SMA_20'] = gold_close.rolling(window=20).mean()
            df['EMA_12'] = gold_close.ewm(span=12).mean()
            
            # Bollinger Bands
            bb_period = 20
            bb_std = gold_close.rolling(window=bb_period).std()
            df['BB_Middle'] = gold_close.rolling(window=bb_period).mean()
            df['BB_Upper'] = df['BB_Middle'] + (bb_std * 2)
            df['BB_Lower'] = df['BB_Middle'] - (bb_std * 2)
            
            # Price changes
            df['Price_Change_1h'] = gold_close.pct_change()
            df['Price_Change_6h'] = gold_close.pct_change(6)
            
            logger.info("üìà –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –¥–æ–±–∞–≤–ª–µ–Ω—ã")
            return df
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤: {e}")
            return df
    
    def _calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:
        """–†–∞—Å—á–µ—Ç RSI"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi
    
    def save_data(self, df: pd.DataFrame, filename: str = None):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            if filename is None:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"enhanced_gold_data_with_sentiment_{timestamp}.csv"
            
            filepath = os.path.join(os.path.dirname(__file__), filename)
            df.to_csv(filepath)
            logger.info(f"üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {filepath}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {e}")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    pipeline = GoldTradingDataPipeline()
    
    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 48 —á–∞—Å–æ–≤
    result_df = pipeline.get_market_data_with_sentiment(hours_back=48)
    
    if not result_df.empty:
        print("\nüìä –ü–æ—Å–ª–µ–¥–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ:")
        print(result_df.tail(5)[['GOLD_Close', 'RSI', 'combined_sentiment', 'fear_greed']].round(4))
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
        pipeline.save_data(result_df, "enhanced_gold_data_with_sentiment_hourly.csv")
        
        print(f"\n‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(result_df)} –∑–∞–ø–∏—Å–µ–π")
        print(f"–í—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω: {result_df.index.min()} - {result_df.index.max()}")
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")


if __name__ == "__main__":
    main()