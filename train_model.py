#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ GRU –º–æ–¥–µ–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è ETH
–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è Mac M3 Pro (Metal Performance Shaders)
"""

import os
import sys
import torch
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import asyncio
import json
from pathlib import Path
import argparse
from tqdm import tqdm

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è Mac M3
if torch.backends.mps.is_available():
    device = torch.device("mps")
    print("üéâ –ò—Å–ø–æ–ª—å–∑—É–µ–º Apple M3 Pro GPU (Metal Performance Shaders)")
else:
    device = torch.device("cpu")
    print("üíª –ò—Å–ø–æ–ª—å–∑—É–µ–º CPU")

# –ò–º–ø–æ—Ä—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã
from config_loader import config
from eth_analysis_system import (
    TelegramParser, 
    NewsRelevanceClassifier,
    TechnicalAnalyzer,
    ETHPricePredictor,
    PricePredictor
)

class GRUTrainer:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ GRU –º–æ–¥–µ–ª–∏"""
    
    def __init__(self):
        self.config = config
        self.device = device
        self.logger = config.logger
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        self.setup_directories()
        
    def setup_directories(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π"""
        dirs = ['models', 'data/raw', 'data/processed', 'logs/training']
        for dir_path in dirs:
            Path(dir_path).mkdir(parents=True, exist_ok=True)
    
    async def collect_telegram_data(self, days_back=30):
        """–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑ Telegram"""
        self.logger.info("üì± –ù–∞—á–∏–Ω–∞–µ–º —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑ Telegram...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        news_cache_path = Path(f"data/raw/telegram_news_{days_back}d.csv")
        
        if news_cache_path.exists():
            self.logger.info("üìÇ –ù–∞–π–¥–µ–Ω –∫—ç—à –Ω–æ–≤–æ—Å—Ç–µ–π, –∑–∞–≥—Ä—É–∂–∞–µ–º...")
            news_df = pd.read_csv(news_cache_path)
            news_df['date'] = pd.to_datetime(news_df['date'])
            return news_df
        
        # –°–æ–±–∏—Ä–∞–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        telegram_config = self.config.get_telegram_config()
        channels = self.config.get_telegram_channels()
        
        parser = TelegramParser(**telegram_config)
        await parser.connect()
        
        try:
            news_df = await parser.parse_multiple_channels(
                channels, 
                days_back=days_back,
                limit=500  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫—ç—à
            news_df.to_csv(news_cache_path, index=False)
            self.logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(news_df)} –Ω–æ–≤–æ—Å—Ç–µ–π –≤ –∫—ç—à")
            
            return news_df
            
        finally:
            await parser.close()
    
    def prepare_technical_data(self, days_back=60):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        self.logger.info("üìä –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ ETH...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        tech_cache_path = Path(f"data/raw/eth_technical_{days_back}d.csv")
        
        if tech_cache_path.exists():
            self.logger.info("üìÇ –ù–∞–π–¥–µ–Ω –∫—ç—à —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö, –∑–∞–≥—Ä—É–∂–∞–µ–º...")
            df = pd.read_csv(tech_cache_path, index_col=0, parse_dates=True)
            return df
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        analyzer = TechnicalAnalyzer()
        df = analyzer.fetch_eth_data(period=f"{days_back}d")
        df = analyzer.calculate_indicators(df)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫—ç—à
        df.to_csv(tech_cache_path)
        self.logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ: {len(df)} –∑–∞–ø–∏—Å–µ–π")
        
        return df
    
    def create_training_dataset(self, tech_df, news_df=None):
        """–°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏"""
        self.logger.info("üîß –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è...")
        
        # –í—ã–±–∏—Ä–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        tech_features = [
            'Open', 'High', 'Low', 'Close', 'Volume',
            'SMA_20', 'SMA_50', 'EMA_12', 'RSI', 
            'MACD', 'ATR', 'OBV', 'Price_change', 'Volatility',
            'BB_width', 'Volume_ratio'
        ]
        
        # –£–±–∏—Ä–∞–µ–º NaN
        df = tech_df[tech_features].dropna()
        
        # –°–æ–∑–¥–∞–µ–º PricePredictor –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        predictor = PricePredictor()
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–æ–≤–æ—Å—Ç–∏, –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∏—Ö
        if news_df is not None and not news_df.empty:
            self.logger.info("üì∞ –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ–º –Ω–æ–≤–æ—Å—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ...")
            X_tech, X_news, y = predictor.prepare_training_data(df, news_df)
        else:
            self.logger.info("‚ö†Ô∏è –û–±—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö")
            # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –±–µ–∑ –Ω–æ–≤–æ—Å—Ç–µ–π
            X_tech, y = self._prepare_tech_only_data(df, predictor)
            X_news = None
        
        self.logger.info(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(X_tech)} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π")
        self.logger.info(f"   –†–∞–∑–º–µ—Ä –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {X_tech.shape[1]}")
        self.logger.info(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {X_tech.shape[2]}")
        
        return X_tech, X_news, y, predictor
    
    def _prepare_tech_only_data(self, df, predictor):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–æ–ª—å–∫–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        features = predictor.technical_scaler.fit_transform(df.values)
        target = predictor.price_scaler.fit_transform(df[['Close']].values)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
        sequence_length = 30
        X, y = [], []
        
        for i in range(sequence_length, len(features) - 1):
            X.append(features[i-sequence_length:i])
            y.append(target[i + 1, 0])  # –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º —Å–ª–µ–¥—É—é—â–∏–π –¥–µ–Ω—å
        
        return torch.FloatTensor(np.array(X)), torch.FloatTensor(np.array(y))
    
    def train_gru_model(self, X_tech, X_news, y, predictor):
        """–¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ GRU –º–æ–¥–µ–ª–∏"""
        self.logger.info("üß† –ù–∞—á–∏–Ω–∞–µ–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É GRU –º–æ–¥–µ–ª–∏...")
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        model_config = self.config.get_model_config()
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        train_size = int(0.7 * len(X_tech))
        val_size = int(0.15 * len(X_tech))
        
        X_tech_train = X_tech[:train_size]
        X_tech_val = X_tech[train_size:train_size + val_size]
        X_tech_test = X_tech[train_size + val_size:]
        
        y_train = y[:train_size]
        y_val = y[train_size:train_size + val_size]
        y_test = y[train_size + val_size:]
        
        if X_news is not None:
            X_news_train = X_news[:train_size]
            X_news_val = X_news[train_size:train_size + val_size]
            X_news_test = X_news[train_size + val_size:]
        else:
            # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            X_news_train = torch.zeros(len(X_tech_train), 5)
            X_news_val = torch.zeros(len(X_tech_val), 5)
            X_news_test = torch.zeros(len(X_tech_test), 5)
        
        self.logger.info(f"üìä –†–∞–∑–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö:")
        self.logger.info(f"   Train: {len(X_tech_train)}")
        self.logger.info(f"   Val: {len(X_tech_val)}")
        self.logger.info(f"   Test: {len(X_tech_test)}")
        
        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        predictor.model = None  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –º–æ–¥–µ–ª—å
        train_losses, val_losses = predictor.train(
            X_tech_train, X_news_train, y_train,
            epochs=model_config['epochs'],
            batch_size=model_config['batch_size']
        )
        
        # –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        self.evaluate_model(predictor, X_tech_test, X_news_test, y_test)
        
        return predictor, train_losses, val_losses
    
    def evaluate_model(self, predictor, X_tech_test, X_news_test, y_test):
        """–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏"""
        self.logger.info("üìà –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        
        predictor.model.eval()
        with torch.no_grad():
            X_tech_test = X_tech_test.to(self.device)
            X_news_test = X_news_test.to(self.device)
            y_test = y_test.to(self.device)
            
            predictions = predictor.model(X_tech_test, X_news_test)
            
            # –ú–µ—Ç—Ä–∏–∫–∏
            mse = torch.nn.functional.mse_loss(predictions.squeeze(), y_test)
            mae = torch.nn.functional.l1_loss(predictions.squeeze(), y_test)
            
            # –û–±—Ä–∞—Ç–Ω–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏
            y_test_orig = predictor.price_scaler.inverse_transform(
                y_test.cpu().numpy().reshape(-1, 1)
            )
            pred_orig = predictor.price_scaler.inverse_transform(
                predictions.cpu().numpy()
            )
            
            # Directional accuracy
            y_diff = np.diff(y_test_orig.flatten())
            pred_diff = np.diff(pred_orig.flatten())
            dir_acc = np.mean(np.sign(y_diff) == np.sign(pred_diff)) * 100
            
            self.logger.info(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
            self.logger.info(f"   MSE: {mse:.6f}")
            self.logger.info(f"   MAE: {mae:.6f}")
            self.logger.info(f"   MAE –≤ $: ${np.mean(np.abs(y_test_orig - pred_orig)):.2f}")
            self.logger.info(f"   Directional Accuracy: {dir_acc:.1f}%")
    
    def save_model(self, predictor, metrics=None):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        model_path = Path(f"models/eth_gru_model_{timestamp}.pth")
        
        save_dict = {
            'model_state_dict': predictor.model.state_dict(),
            'technical_scaler': predictor.technical_scaler,
            'price_scaler': predictor.price_scaler,
            'config': self.config.get_model_config(),
            'timestamp': timestamp,
            'device': str(self.device),
            'metrics': metrics
        }
        
        torch.save(save_dict, model_path)
        self.logger.info(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –ø–æ—Å–ª–µ–¥–Ω—é—é –º–æ–¥–µ–ª—å
        latest_path = Path("models/eth_gru_model_latest.pth")
        torch.save(save_dict, latest_path)
        self.logger.info(f"üíæ –û–±–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ—Å–ª–µ–¥–Ω—è—è –º–æ–¥–µ–ª—å: {latest_path}")
        
        return model_path
    
    def plot_training_history(self, train_losses, val_losses):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è"""
        import matplotlib.pyplot as plt
        
        plt.figure(figsize=(10, 6))
        plt.plot(train_losses, label='Train Loss', alpha=0.8)
        plt.plot(val_losses, label='Validation Loss', alpha=0.8)
        plt.title('GRU Model Training History')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫
        plot_path = Path("logs/training/training_history.png")
        plt.savefig(plot_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        self.logger.info(f"üìä –ì—Ä–∞—Ñ–∏–∫ –æ–±—É—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {plot_path}")

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏"""
    parser = argparse.ArgumentParser(description='Train ETH GRU Model')
    parser.add_argument('--days-back', type=int, default=30,
                       help='Days of historical data to use')
    parser.add_argument('--skip-telegram', action='store_true',
                       help='Skip Telegram data collection')
    parser.add_argument('--epochs', type=int, default=None,
                       help='Override number of epochs from config')
    
    args = parser.parse_args()
    
    print("""
    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
    ‚ïë     ETH GRU Model Training             ‚ïë
    ‚ïë       Mac M3 Pro Optimized             ‚ïë
    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """)
    
    trainer = GRUTrainer()
    
    try:
        # 1. –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö
        print("\nüìä –≠—Ç–∞–ø 1: –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö")
        print("=" * 50)
        
        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
        tech_df = trainer.prepare_technical_data(days_back=args.days_back * 2)
        
        # Telegram –¥–∞–Ω–Ω—ã–µ
        news_df = None
        if not args.skip_telegram:
            try:
                news_df = await trainer.collect_telegram_data(days_back=args.days_back)
            except Exception as e:
                trainer.logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ Telegram: {e}")
                trainer.logger.info("–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ç–æ–ª—å–∫–æ —Å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏...")
        
        # 2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        print("\nüîß –≠—Ç–∞–ø 2: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
        print("=" * 50)
        
        X_tech, X_news, y, predictor = trainer.create_training_dataset(
            tech_df, news_df
        )
        
        # 3. –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏
        print("\nüß† –≠—Ç–∞–ø 3: –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ GRU –º–æ–¥–µ–ª–∏")
        print("=" * 50)
        
        if args.epochs:
            # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
            config.env_config['model']['epochs'] = args.epochs
        
        predictor, train_losses, val_losses = trainer.train_gru_model(
            X_tech, X_news, y, predictor
        )
        
        # 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print("\nüíæ –≠—Ç–∞–ø 4: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        print("=" * 50)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
        model_path = trainer.save_model(predictor, {
            'final_train_loss': train_losses[-1],
            'final_val_loss': val_losses[-1]
        })
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        trainer.plot_training_history(train_losses, val_losses)
        
        print("\n‚úÖ –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        print(f"üìä –§–∏–Ω–∞–ª—å–Ω–∞—è train loss: {train_losses[-1]:.6f}")
        print(f"üìä –§–∏–Ω–∞–ª—å–Ω–∞—è val loss: {val_losses[-1]:.6f}")
        print(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")
        
        # 5. –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        print("\nüîÆ –¢–µ—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –∑–∞–≤—Ç—Ä–∞:")
        print("=" * 50)
        
        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ
        last_sequence = X_tech[-1:].to(trainer.device)
        last_news = X_news[-1:].to(trainer.device) if X_news is not None else torch.zeros(1, 5).to(trainer.device)
        
        predictor.model.eval()
        with torch.no_grad():
            prediction = predictor.model(last_sequence, last_news)
            pred_price = predictor.price_scaler.inverse_transform(
                prediction.cpu().numpy()
            )[0, 0]
            
            current_price = tech_df['Close'].iloc[-1]
            change_pct = ((pred_price - current_price) / current_price) * 100
            
            print(f"üí∞ –¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞ ETH: ${current_price:.2f}")
            print(f"üìà –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –∑–∞–≤—Ç—Ä–∞: ${pred_price:.2f}")
            print(f"üìä –û–∂–∏–¥–∞–µ–º–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ: {change_pct:+.2f}%")
        
    except Exception as e:
        trainer.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–µ: {e}")
        raise

if __name__ == "__main__":
    # –î–ª—è Mac M3 Pro –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
    if torch.backends.mps.is_available():
        # –í–∫–ª—é—á–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è Metal
        torch.backends.mps.allow_tf32 = True
    
    asyncio.run(main())